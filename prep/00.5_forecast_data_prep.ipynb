{
 "cells": [
  {
   "cell_type": "raw",
   "id": "28bb0428",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"00.5_forecast_data_prep\"\n",
    "author: \"JTK\"\n",
    "date: \"2025-05-21\"\n",
    "output: html_document\n",
    "editor_options: \n",
    "  chunk_output_type: console\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cbc0e",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa16bc3",
   "metadata": {},
   "source": [
    "# Housekeeping\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d4c6a",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data mgmt\n",
    "require(tidyverse)\n",
    "\n",
    "## Parallel computing\n",
    "require(future)\n",
    "require(furrr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea27466",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Pull-in and manipulate forecasts\n",
    "\n",
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Set forecast file location and list all the files located there\n",
    "\n",
    "loc <- here(\"output-data/nwm_operational/medium_term/\")\n",
    "\n",
    "mt_files <- list.files(loc)\n",
    "\n",
    "mt_downloads <- list()\n",
    "\n",
    "#### Import all the downloaded files\n",
    "\n",
    "for(i in 1:length(mt_files)){\n",
    "  \n",
    "  file_name <- here(loc, mt_files[i])\n",
    "  \n",
    "  mt <- read_csv(file_name)\n",
    "  \n",
    "  mt_downloads[[i]] <- mt \n",
    "  \n",
    "  \n",
    "}\n",
    "\n",
    "#### Trim down to Lake Champlain gages\n",
    "\n",
    "mt_downloads_lc <- map(mt_downloads, ~(.x %>%\n",
    "                                         filter(as.character(comid) %in% \n",
    "                                                  lc_gages_metadata_clean$comid)),\n",
    "                       .progress = TRUE)\n",
    "\n",
    "#### Make tibble\n",
    "\n",
    "mt_downloads_lc <- bind_rows(mt_downloads_lc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2da9b7",
   "metadata": {},
   "source": [
    "### Convert to daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "  nwm_daily <- mt_downloads_lc %>%\n",
    "    mutate(predict_date = as_date(predict_dateTime)) %>%\n",
    "    dplyr::group_by(comid, init_date, member, predict_date) %>%\n",
    "    summarise(forecasted_q_cms = mean(modeled_q_cms)) %>%\n",
    "    dplyr::ungroup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd9f90",
   "metadata": {},
   "source": [
    "### Take mean of all members and convert flow to cms/km2 \n",
    "\n",
    "######## Normalize by drainage area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c16b31",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "##### Combine all members and take the mean\n",
    "##### And transform discharge by normalizing by drainage area\n",
    "##### And taking the log\n",
    "\n",
    "nwm_daily_mean_forecast_lc_tribs <- nwm_daily %>%\n",
    "  mutate(comid = as.character(comid)) %>%\n",
    "  dplyr::group_by(comid, init_date, predict_date) %>%\n",
    "  summarise(mean_forecasted_q_cms = mean(forecasted_q_cms)) %>%\n",
    "  dplyr::ungroup() %>%\n",
    "  dplyr::group_by(comid) %>%\n",
    "  dplyr::arrange(init_date, .by_group = TRUE) %>%\n",
    "  dplyr::ungroup() %>%\n",
    "  mutate(lead_days = as.numeric(predict_date - init_date)) %>%\n",
    "  inner_join(., lc_gages_metadata_clean %>%\n",
    "               rename(drnarea_km2 = drain_area_km2) %>%\n",
    "               dplyr::select(tributary, site_no, comid,drnarea_km2) %>%\n",
    "               mutate(comid = as.character(comid)),\n",
    "             by = \"comid\") %>%\n",
    "  mutate(mean_forecasted_q_cms_km2 = mean_forecasted_q_cms/drnarea_km2) %>%\n",
    "  mutate(mean_forecasted_log_q_cms_km2 = log10(mean_forecasted_q_cms_km2))\n",
    "\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360f8b7",
   "metadata": {},
   "source": [
    "# Calculate various flow variables\n",
    "\n",
    "### Antecedent conditions\n",
    "\n",
    "This is mostly challenging because at longer leadtimes, \"antecedent\" conditions \n",
    "become a mixture of forecasted and observed values. So for, say, a three day lead time\n",
    "weekly antecedent discharge day 1 would have four days of observed discharge (day 4,5,6,7)\n",
    "and three days of forecasted discharge (1,2,3); on day 2, three days of observed and four days \n",
    "of forecasted, and so on and so forth. So we need to build a dataframe that reflects this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60babb37",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### First, make sure the observed data is arranged by date and station\n",
    "\n",
    "observed_flow_for_nwm_predictions <- flow_data_july2024_transform %>%\n",
    "  dplyr::group_by(tributary) %>%\n",
    "  arrange(date, .by_group = TRUE) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#### Create a lookup table to determine which timesteps \n",
    "#### For which we need antecedent values \n",
    "\n",
    "timesteps_needed <- nwm_daily_mean_forecast_lc_tribs %>%\n",
    "      ungroup() %>%\n",
    "      mutate(days_needed_from_gage_weekly_ant = 7 - lead_days) %>%\n",
    "      mutate(days_needed_from_gage_weekly_ant = \n",
    "               ifelse(days_needed_from_gage_weekly_ant < 0, 0, \n",
    "                    days_needed_from_gage_weekly_ant)) %>%\n",
    "      mutate(days_needed_from_nwm_weekly_ant = 7 - days_needed_from_gage_weekly_ant) %>%\n",
    "      mutate(days_needed_from_gage_monthly_ant = 30 - lead_days) %>%\n",
    "      mutate(days_needed_from_gage_monthly_ant = \n",
    "               ifelse(days_needed_from_gage_monthly_ant < 0, 0, \n",
    "                    days_needed_from_gage_monthly_ant)) %>%\n",
    "      mutate(days_needed_from_nwm_monthly_ant = (30) - \n",
    "               days_needed_from_gage_monthly_ant) %>%\n",
    "          dplyr::select( comid, lead_days, init_date, predict_date, \n",
    "                      days_needed_from_gage_weekly_ant, \n",
    "                      days_needed_from_nwm_weekly_ant,\n",
    "                      days_needed_from_gage_monthly_ant, \n",
    "                      days_needed_from_nwm_monthly_ant,\n",
    "                     ) %>%\n",
    "  inner_join(., lc_gages_metadata_clean %>%\n",
    "               mutate(comid = as.character(comid)) %>%\n",
    "               dplyr::select(site_no, comid),\n",
    "             by = \"comid\")\n",
    "  \n",
    "\n",
    "#### Find antecedent conditions for all LC gages for each forecasted data\n",
    "#### in water year 2022-2023\n",
    "\n",
    "flow_ants_lc <- purrr::pmap_dfr(list(predict_date = timesteps_needed$predict_date,\n",
    "                          init_date = timesteps_needed$init_date,\n",
    "                          site_no = timesteps_needed$site_no,\n",
    "                          days_from_gage =\n",
    "                            timesteps_needed$days_needed_from_gage_weekly_ant,\n",
    "                          days_from_model =\n",
    "                            timesteps_needed$days_needed_from_nwm_weekly_ant,\n",
    "                monthly_days_from_gage =\n",
    "                  timesteps_needed$days_needed_from_gage_monthly_ant,\n",
    "                monthly_days_from_model =\n",
    "                  timesteps_needed$days_needed_from_nwm_monthly_ant\n",
    "                          ),\n",
    "                .f = possibly(antecedent_calculator,\n",
    "                      otherwise = tibble(mean_prior_weekly_log_q_cms_km2 = NA, \n",
    "                                         mean_prior_monthly_log_q_cms_km2 = NA)),\n",
    "                \n",
    "                obs_df = observed_flow_for_nwm_predictions,\n",
    "                model_df = nwm_daily_mean_forecast_lc_tribs,\n",
    "                .progress = TRUE)\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b09780",
   "metadata": {},
   "source": [
    "### Delta Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655d0da",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Calculate the delta q\n",
    "\n",
    "delta_q <- limb_getter(nwm_daily_mean_forecast_lc_tribs,\n",
    "                         observed_flow_for_nwm_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db6aa9",
   "metadata": {},
   "source": [
    "### Combine antecedent and delta Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ada6c",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "antecedent_flow <- bind_cols(nwm_daily_mean_forecast_lc_tribs, \n",
    "                             flow_ants_lc) %>%\n",
    "  inner_join(., \n",
    "             delta_q,\n",
    "             by = c(\"predict_date\", \"init_date\", \"tributary\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00ebd9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Put all the flow conditions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2224f45",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nwm_flow_and_antecedents <- antecedent_flow %>%\n",
    "  dplyr::select(!delta_daily_q_cat) %>%\n",
    "  mutate(day_of_year = yday(predict_date)) %>%\n",
    "  dplyr::mutate(season = case_when(day_of_year %in% seq(60,151,1) ~ \"Spring\",\n",
    "                                   day_of_year %in% seq(152,243,1) ~ \"Summer\",\n",
    "                                   day_of_year %in% seq(244,334,1) ~ \"Fall\",\n",
    "                                   day_of_year > 334 | day_of_year < 60 ~ \"Winter\")) %>%\n",
    "  mutate(water_year = add_waterYear(predict_date)) %>%\n",
    "  dplyr::select(!day_of_year) %>%\n",
    "  rename(log_daily_q = mean_forecasted_log_q_cms_km2,\n",
    "         mean_prior_weekly_q = mean_prior_weekly_log_q_cms_km2,\n",
    "         mean_prior_monthly_q = mean_prior_monthly_log_q_cms_km2,\n",
    "         ) %>%\n",
    "  dplyr::select(tributary, \n",
    "                init_date, predict_date, lead_days,\n",
    "                log_daily_q, \n",
    "                mean_prior_weekly_q, mean_prior_monthly_q, lag_daily_q,\n",
    "                delta_daily_q,\n",
    "                season,\n",
    "                water_year\n",
    "                )\n",
    "\n",
    "################################################################################\n",
    "\n",
    "#### Read from file if already done\n",
    "\n",
    "#nwm_flow_and_antecedents <- read_csv(here(\"input-data/nwm_flow_and_antecedents.csv\"))\n",
    "\n",
    "\n",
    "#################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3cf63",
   "metadata": {},
   "source": [
    "####################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
    "\n",
    "# Functions\n",
    "\n",
    "This function essentially calculates various antecedent conditions to be used in\n",
    "a forecasting scenario. Importantly, this requires combining observations AND \n",
    "forecasted values for a given forecast timestep, meaning that, for example, forecasted flow \n",
    "for Oct 31st 2022 has a weekly antecedent discharge of seven observed values for a forecast \n",
    "with lead time of zero days (so the one issued Oct 31st at midnight); of six observed and one\n",
    "forecasted for a forecast with a lead time of one day (so issued at Oct 30th); and so on. This is \n",
    "kinda complicated to create a dataframe that follows this format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cb755",
   "metadata": {
    "lines_to_next_cell": 0,
    "name": "antecedent_calculator"
   },
   "outputs": [],
   "source": [
    "\n",
    "antecedent_calculator <- function(predict_date,\n",
    "                                  init_date,\n",
    "                                  site_no,\n",
    "                              days_from_gage = NULL, \n",
    "                              days_from_model = NULL,\n",
    "                              monthly_days_from_gage = NULL,\n",
    "                              monthly_days_from_model = NULL,\n",
    "                              obs_df = NULL,\n",
    "                              model_df = NULL\n",
    "                              ) {\n",
    "\n",
    "  \n",
    "########################## SET UP ##############################################\n",
    "  \n",
    "  ### Find the index of the dateTime of interest in the observed data (minus 1)\n",
    "  \n",
    "  date_index_obs <- which(obs_df$date == predict_date &\n",
    "                                obs_df$site_no == site_no) \n",
    "  \n",
    "  ### Find the index of thepredict  date\n",
    "  \n",
    "  date_index_model <- which(model_df$predict_date == predict_date & \n",
    "                              model_df$site_no == site_no & \n",
    "                              model_df$init_date == init_date\n",
    "                              )\n",
    "  \n",
    "  ########## WEEKLY ANTECEDENTS ###################################################\n",
    "  \n",
    "  ### Calculate weekly antecedents based on values calculated in the \n",
    "  ### timesteps_needed step\n",
    "  \n",
    "    if (days_from_gage != 0){\n",
    "          log_obs_flow <- obs_df %>%\n",
    "            dplyr::ungroup() %>%\n",
    "            dplyr::slice(((date_index_obs - days_from_model) - days_from_gage):\n",
    "                           (date_index_obs - days_from_model - 1)) %>%\n",
    "            .$log_daily_q\n",
    "          \n",
    "        \n",
    "    } else{\n",
    "        \n",
    "      log_obs_flow <- NA\n",
    "      \n",
    "      } ### End log observed flow ifelse \n",
    "\n",
    "    if(days_from_model != 0 ){\n",
    "      \n",
    "          log_modeled_flow <- model_df %>%\n",
    "            dplyr::ungroup() %>%\n",
    "            dplyr::slice((date_index_model - days_from_model):(date_index_model -\n",
    "                                                                  1)) %>%\n",
    "            .$mean_forecasted_log_q_cms_km2\n",
    "        \n",
    "      \n",
    "        }  else {\n",
    "        \n",
    "        log_modeled_flow <- NA\n",
    "      }\n",
    "\n",
    "\n",
    "    obs_and_modeled_flow <-  c(log_obs_flow, log_modeled_flow) %>%\n",
    "      na.omit() \n",
    "      \n",
    "      mean_prior_weekly_flow <- mean(obs_and_modeled_flow) %>%\n",
    "            as_tibble() %>%\n",
    "            rename(mean_prior_weekly_log_q_cms_km2 = 1)\n",
    "  \n",
    "\n",
    "  ################################################################################\n",
    "    \n",
    "  ############# MONTHLY ANTECEDENTS ##############################################\n",
    "\n",
    "    if (monthly_days_from_gage > 0 & monthly_days_from_model <= 7){\n",
    "\n",
    "          log_obs_flow_minus3 <- obs_df %>%\n",
    "            dplyr::slice((date_index_obs - 30):(date_index_obs -\n",
    "                                                       7)) %>%\n",
    "            .$log_daily_q\n",
    "\n",
    "          obs_and_modeled_flow_monthly <- c(obs_and_modeled_flow,\n",
    "                                            log_obs_flow_minus3) %>%\n",
    "            na.omit()\n",
    "\n",
    "    } else if(monthly_days_from_model > 7) {\n",
    "\n",
    "      log_modeled_flow_monthly <- model_df %>%\n",
    "            dplyr::slice((date_index_model -\n",
    "                            monthly_days_from_model):(date_index_model - 1)) %>%\n",
    "            .$mean_forecasted_log_q_cms_km2\n",
    "\n",
    "      log_observed_flow_monthly <- obs_df %>%\n",
    "            dplyr::slice(((date_index_obs - monthly_days_from_model)\n",
    "                          - monthly_days_from_gage):(date_index_obs -\n",
    "                                                        monthly_days_from_model - 1)) %>%\n",
    "            .$log_daily_q\n",
    "\n",
    "      obs_and_modeled_flow_monthly <- c(log_modeled_flow_monthly,\n",
    "                                        log_observed_flow_monthly) %>%\n",
    "        na.omit()\n",
    "\n",
    "    } else {\n",
    "\n",
    "      obs_and_modeled_flow_monthly <- NA\n",
    "\n",
    "    }\n",
    "      \n",
    "            mean_prior_monthly_flow <- mean(obs_and_modeled_flow_monthly) %>%\n",
    "            as_tibble() %>%\n",
    "            rename(mean_prior_monthly_log_q_cms_km2 = 1)\n",
    "            \n",
    "            weekly_and_monthly_ant <- bind_cols(mean_prior_weekly_flow, \n",
    "                                                mean_prior_monthly_flow)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59be0ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77c24a3",
   "metadata": {},
   "source": [
    "This function calculates the change in discharge from time t-1 to time t. It \n",
    "calculates this as both a raw numeric and then a categorical variable with\n",
    "three possible values of -1, 0, and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e252cb3",
   "metadata": {
    "lines_to_next_cell": 0,
    "name": "limb_getter"
   },
   "outputs": [],
   "source": [
    "\n",
    "limb_getter <- function(model_df, observed_df){\n",
    "  \n",
    "  \n",
    "  model_df %>%\n",
    "    mutate(init_date_minus_one = init_date - days(1)) %>%\n",
    "    group_by(init_date, tributary, site_no, comid) %>% #### This is to calculate limb\n",
    "    mutate(delta_q_modeled = mean_forecasted_q_cms_km2  - \n",
    "             lag(mean_forecasted_q_cms_km2 )) %>%\n",
    "    mutate(modeled_lag_daily_q = lag(mean_forecasted_log_q_cms_km2\n",
    "                                     )) %>%\n",
    "    mutate(delta_q_q_modeled = \n",
    "             abs(delta_q_modeled/lag(mean_forecasted_q_cms_km2))*sign(delta_q_modeled)) %>%\n",
    "    inner_join(., observed_flow_for_nwm_predictions %>%\n",
    "                 dplyr::select(tributary, site_no,\n",
    "                               date, log_daily_q),\n",
    "               join_by(init_date_minus_one == date,\n",
    "                       tributary == tributary,\n",
    "                       site_no == site_no)) %>%\n",
    "    mutate(delta_q_day_zero = mean_forecasted_q_cms_km2 - 10^log_daily_q) %>%\n",
    "    mutate(delta_q_q_day_zero = abs(delta_q_day_zero/10^log_daily_q)*sign(delta_q_day_zero)) %>%\n",
    "    mutate(delta_q_q = coalesce(delta_q_q_modeled, delta_q_q_day_zero)) %>%\n",
    "    group_by(init_date, tributary, site_no, comid) %>% #### This is to calculate limb\n",
    "    mutate(delta_q_modeled = mean_forecasted_log_q_cms_km2 - \n",
    "             lag(mean_forecasted_log_q_cms_km2)) %>% ## Update\n",
    "    mutate(delta_q_day_zero = mean_forecasted_log_q_cms_km2 - \n",
    "             log_daily_q) %>% ### Replace w/ log\n",
    "    mutate(delta_q = coalesce(delta_q_modeled, delta_q_day_zero)) %>%\n",
    "    rename(delta_daily_q = delta_q) %>%\n",
    "    mutate(lag_daily_q = coalesce(modeled_lag_daily_q, log_daily_q)) %>%\n",
    "    dplyr::ungroup() %>%\n",
    "    mutate(delta_daily_q_cat = case_when(delta_q_q > 0.10 ~ 1,\n",
    "                                       delta_q_q < -0.10 ~ -1,\n",
    "                                       (delta_q_q <= 0.10 & delta_q_q >= -0.10) ~ 0)) %>%\n",
    "    mutate(delta_daily_q_cat = as.factor(delta_daily_q_cat)) %>%\n",
    "    dplyr::select(c(predict_date, init_date, tributary,\n",
    "                    delta_daily_q, \n",
    "                    delta_daily_q_cat,\n",
    "                    lag_daily_q))\n",
    "    \n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b55781",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "eval,tags,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
