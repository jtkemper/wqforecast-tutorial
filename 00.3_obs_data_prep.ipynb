{
 "cells": [
  {
   "cell_type": "raw",
   "id": "17897df5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"00.3_obs_data_prep\"\n",
    "author: \"JTK\"\n",
    "date: \"2025-05-02\"\n",
    "output: html_document\n",
    "editor_options: \n",
    "  chunk_output_type: console\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4c00e",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5b93a",
   "metadata": {},
   "source": [
    "################################################################################\n",
    "\n",
    "This script manipulates and cleans the observational data (discharge, water quality)\n",
    "in order to get it reading for model construction. It also splits data into training,\n",
    "validation, and testing sets.\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "Three dataframes with monitoring data and watershed attributes:\n",
    "\n",
    "1) `flow_data_clean` (*from 00.1_obs_data_download_and_clean*)\n",
    "\n",
    "2) `lc_tribs_wq_all` (*from 00.1_obs_data_download_and_clean download*)\n",
    "\n",
    "3) `watershed_chars` (*from 00.2_watershed_attributes_downloads*)\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "1) Dataframe with observational concentration data and all possible drivers for \n",
    "total phosphorus and chloride (`tp_drivers`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dadd0b5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "################################################################################\n",
    "\n",
    "# Housekeeping\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880440b",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### Data mgmt\n",
    "require(tidyverse)\n",
    "require(zoo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d544bf8",
   "metadata": {},
   "source": [
    "# Data Cleaning & Prep\n",
    "\n",
    "### Transform to log and add in antecedent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f7fd2",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#### First, transform normalized discharge (m3/s/km2) to log-scale\n",
    "#### Then, calculate daily, weekly, and monthly discharge\n",
    "#### Calculate the the change in discharge from time t to time t-1\n",
    "#### Calculate that change normalized by discharge at time t-1\n",
    "#### And then also transform that into a categorical \"rise/fall\"\n",
    "#### based on whether it is positive (rise) or negative (fall)\n",
    "#### And finally determine a \"season\" categorical variable\n",
    "\n",
    "\n",
    "flow_data_transform <- flow_data_clean %>% \n",
    "  mutate(discharge_cms_km2 = discharge_cms/(drnarea_km2)) %>%\n",
    "  dplyr::select(tributary, site_no,\n",
    "                date, waterYear,\n",
    "                discharge_cms_km2) %>%\n",
    "  dplyr::ungroup() %>%\n",
    "  dplyr::group_by(tributary) %>%\n",
    "  arrange(date, .by_group = TRUE) %>%\n",
    "  mutate(log_daily_q = log10(discharge_cms_km2)) %>%\n",
    "  mutate(mean_prior_weekly_q = rollapply(log_daily_q,\n",
    "                                         width = list(-(7:1)),\n",
    "                                         FUN = mean, align = \"right\",\n",
    "                                         fill= NA)) %>%\n",
    "  mutate(mean_prior_monthly_q = rollapply(log_daily_q,\n",
    "                                         width = list(-(30:1)),\n",
    "                                         FUN = mean, align = \"right\",\n",
    "                                         fill= NA)) %>%\n",
    "  mutate(delta_daily_q = discharge_cms_km2 - lag(discharge_cms_km2)) %>%\n",
    "  mutate(lag_daily_q = lag(log_daily_q)) %>%\n",
    "  mutate(dq_q = abs(delta_daily_q/lag(discharge_cms_km2))*sign(delta_daily_q)) %>%\n",
    "  mutate(delta_daily_q_cat = case_when(dq_q > 0.10 ~ 1,\n",
    "                                       dq_q < -0.10 ~ -1,\n",
    "                                       (dq_q <= 0.10 & dq_q >= -0.10) ~ 0)) %>%\n",
    "  mutate(delta_daily_q = log_daily_q - lag(log_daily_q)) %>% ### Update\n",
    "  mutate(delta_daily_q_cat = as.factor(delta_daily_q_cat)) %>%\n",
    "  mutate(day_of_year = yday(date)) %>%\n",
    "  dplyr::slice(-(1:30)) %>% ### Remove first thirty days of record \n",
    "  dplyr::select(tributary, site_no, \n",
    "                date, waterYear, \n",
    "                day_of_year,\n",
    "                log_daily_q,\n",
    "                mean_prior_weekly_q, \n",
    "                mean_prior_monthly_q,\n",
    "                delta_daily_q, \n",
    "                delta_daily_q_cat,\n",
    "                lag_daily_q) %>%\n",
    "  rename(water_year = waterYear) %>% ### Better follows our naming conventions\n",
    "  dplyr::ungroup() %>%\n",
    "  tidyr::drop_na(mean_prior_monthly_q) %>%\n",
    "  tidyr::drop_na(tributary) %>%\n",
    "  mutate(date = as_date(date)) %>%\n",
    "  dplyr::mutate(season = case_when(day_of_year %in% seq(60,151,1) ~ \"Spring\",\n",
    "                                   day_of_year %in% seq(152,243,1) ~ \"Summer\",\n",
    "                                   day_of_year %in% seq(244,334,1) ~ \"Fall\",\n",
    "                                   day_of_year > 334 | day_of_year < 60 ~ \"Winter\")) %>%\n",
    "  dplyr::select(!day_of_year) ### Remove day of year\n",
    "  \n",
    "\n",
    "tp_data <- read_csv(here(\"input-data/tp_and_chlor_water_quality_data_clean.csv\"))\n",
    "\n",
    "tp_data2 <- tp_data %>%\n",
    "  filter(str_detect(constituent, \"Phos\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d90364",
   "metadata": {},
   "source": [
    "### Transfrom VTDEC water quality monitoring data to log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lc_tribs_wq_all_clean <- lc_tribs_wq_all_clean %>%\n",
    "  mutate(log_conc = log10(conc)) %>% ### Transform to log\n",
    "  dplyr::select(!conc) ### Remove raw concentration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4f5f4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Combine datasets\n",
    "\n",
    "### Join discharge and water quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e1fa6",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Join them together\n",
    "\n",
    "tribs_wq_and_q_all <- inner_join(flow_data_transform, \n",
    "                                 lc_tribs_wq_all_clean,\n",
    "                                 by = c(\"tributary\", \"date\")) %>%\n",
    "  dplyr::ungroup()\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4c2e7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Join combined water quality & discharge data to watershed attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b221ca",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Do it \n",
    "\n",
    "all_drivers <- tribs_wq_and_q_all %>%\n",
    "  inner_join(., watershed_chars,\n",
    "             by = \"tributary\") %>%\n",
    "  filter(water_year < 2024) ### Remove data from water year 2024\n",
    "\n",
    "#### Split into Total Phosphorus and Chloride dataframes\n",
    "#### Also add a numerical ID field that uniquely represents each tributary\n",
    "#### This will make it easier to make certain model train/valid/splits\n",
    "\n",
    "##### For total phosphorus\n",
    "\n",
    "tp_drivers <- all_drivers %>%\n",
    "  filter(constituent == \"Phosphorus_Total\") %>%\n",
    "  group_by(tributary) %>%\n",
    "  mutate(group_id = cur_group_id()) %>%\n",
    "  dplyr::ungroup() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1713dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Make final modeling dataframes\n",
    "\n",
    "### Remove unsplittable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46deb160",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### We want check to make sure each feature has at least two unique values across\n",
    "#### all cross validation data sets \n",
    "#### This removes features that would have limited explainability in a leave-one-out\n",
    "#### cross validation scenario and might instead \"identify\" a specific basin \n",
    "#### Rather than reflect, in some way, physical/chemical process(es)\n",
    "#### We've written a small function to do so\n",
    "\n",
    "#### Find the unsplittable features\n",
    "\n",
    "##### This can really be any of the constituent driver dataframes\n",
    "##### because these are likely to be static attributes\n",
    "##### but just to be safe lets do it for both\n",
    "\n",
    "\n",
    "##### Make an empty list to save things\n",
    "  \n",
    "small_feats <- list()\n",
    "    \n",
    "##### Loop over each basin \n",
    "    \n",
    "for(i in 1:18) {\n",
    "        \n",
    "        #### Track across basins\n",
    "        \n",
    "        removed_trib <- tp_drivers %>%\n",
    "          filter(group_id == i) %>%\n",
    "          .$tributary %>%\n",
    "          .[1]\n",
    "              \n",
    "              \n",
    "        print(removed_trib)\n",
    "              \n",
    "        #### Determine how many unique values there are for each feature\n",
    "              \n",
    "        small_feats[[i]] <- tp_drivers %>%\n",
    "          filter(group_id != i) %>%\n",
    "          dplyr::select(!c(constituent, \n",
    "                           site_no,\n",
    "                           drnarea_km2)) %>%\n",
    "          dplyr::select(!c(log_conc,\n",
    "                           date, \n",
    "                           water_year,\n",
    "                           tributary,\n",
    "                           group_id)) %>%\n",
    "          summarise(across(everything(), ~length(unique(.x)))) %>% ### How many unique\n",
    "          pivot_longer(everything(), \n",
    "                       values_to = \"unique_feature_values\",\n",
    "                       names_to = \"feature\") %>%\n",
    "          mutate(feature_value_rank = dense_rank(unique_feature_values)) %>%\n",
    "          filter(feature_value_rank == 1) %>%\n",
    "          dplyr::select(!feature_value_rank) %>%\n",
    "          mutate(removed_trib = removed_trib)\n",
    "                \n",
    "      \n",
    "      } ## End for loop\n",
    "      \n",
    "      all_small_feats <- bind_rows(small_feats)\n",
    "      \n",
    "      #### Get features that only have one unique value across at least one\n",
    "      #### Cross-validation split \n",
    "      \n",
    "      unsplittable_feats_tp <- all_small_feats %>%\n",
    "        filter(unique_feature_values < 2) %>%\n",
    "        .$feature\n",
    "\n",
    "#### Remove those from the drivers data frame\n",
    "\n",
    "tp_drivers <- tp_drivers %>%\n",
    "  dplyr::select(!unsplittable_feats_tp)\n",
    "\n",
    "\n",
    "#### Check to make sure it worked \n",
    "\n",
    "unsplittable_feats_tp %in% names(tp_drivers)\n",
    "\n",
    "\n",
    "tp_drivers <- tp_drivers %>%\n",
    "  mutate(wateryear = as.character(water_year))\n",
    "\n",
    "tp_drivers <- read_csv(here(\"input-data/tp_drivers.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f127ecc1",
   "metadata": {},
   "source": [
    "# Then, divide into training & testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Do it\n",
    "\n",
    "tp_train_valid <- tp_drivers %>%\n",
    "  filter(water_year < 2019)\n",
    "\n",
    "tp_test <- tp_drivers %>%\n",
    "  filter(water_year >= 2019)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e49c0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Transform further\n",
    "\n",
    "#### Now transform, by subracting mean and std deviation of each vat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42735e6d",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Scale training data\n",
    "\n",
    "tp_train_scaled <- tp_train_valid %>%\n",
    "  mutate(across(where(is.numeric), ~(.x - mean(.x))/sd(.x)))  %>%\n",
    "  mutate(wateryear = as.numeric(wateryear))\n",
    "\n",
    "tp_train_scalars <- tp_train_valid %>%\n",
    "  summarise(across(where(is.numeric), \n",
    "                   list(mean = ~mean(.x),\n",
    "                        sd = ~sd(.x)),\n",
    "            .names = \"{.col}xxx{.fn}\"))%>%\n",
    "  pivot_longer(everything(),\n",
    "               #names_to = \"metric\",\n",
    "               names_to = c(\".value\", \"metric\"),\n",
    "               names_sep = \"xxx\") \n",
    "\n",
    "tp_train_scalars_conc <- tp_train_scalars %>%\n",
    "  dplyr::select(metric, log_conc)\n",
    "\n",
    "write_csv(tp_train_scalars_conc, here(\"output-data/train_scalars.csv\"))\n",
    "\n",
    "##### Scale testing data\n",
    "\n",
    "tp_test_scaled <- tp_test %>%\n",
    "  mutate(across(where(is.numeric), ~(.x - mean(.x))/sd(.x))) %>%\n",
    "  mutate(wateryear = as.numeric(wateryear))\n",
    "\n",
    "tp_test_scalars <- tp_test %>%\n",
    "  summarise(across(where(is.numeric), \n",
    "                   list(mean = ~mean(.x),\n",
    "                        sd = ~sd(.x)),\n",
    "            .names = \"{.col}xxx{.fn}\"))%>%\n",
    "  pivot_longer(everything(),\n",
    "               #names_to = \"metric\",\n",
    "               names_to = c(\".value\", \"metric\"),\n",
    "               names_sep = \"xxx\")\n",
    "\n",
    "tp_test_scalars_conc <- tp_test_scalars %>%\n",
    "  dplyr::select(metric, log_conc)\n",
    "\n",
    "write_csv(tp_test_scalars_conc, here(\"output-data/test_scalars.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8254b659",
   "metadata": {},
   "source": [
    "# Now, finally, pick the vars for the model types\n",
    "\n",
    "#### Simplest model - just flow and conc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tp_simplest_train <- tp_train_scaled %>%\n",
    "  dplyr::select(tributary, date, wateryear, log_conc, log_daily_q)\n",
    "\n",
    "tp_simplest_test <- tp_test_scaled %>%\n",
    "  dplyr::select(names(tp_simplest_train))\n",
    "\n",
    "write_csv(tp_simplest_test, \"input-data/tp_simplest_test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c376c6d",
   "metadata": {},
   "source": [
    "##### More complex - include antecedent conditions & season (dynamic params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ef56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tp_mrcomp_train <- tp_train_scaled %>%\n",
    "  dplyr::select(names(flow_data_transform), wateryear) \n",
    "\n",
    "tp_mrcomp_train <- tp_test_scaled %>%\n",
    "  dplyr::select(names(tp_mrcomp_train)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ee70e",
   "metadata": {},
   "source": [
    "##### Most complex - all ants and static watershed chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639efc0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "tp_mstcomp_train <- tp_train_scaled\n",
    "\n",
    "tp_mstcompt_test <- tp_test_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909810ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "eval,tags,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
