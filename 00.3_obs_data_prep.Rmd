---
title: "00.3_obs_data_prep"
author: "JTK"
date: "2025-05-02"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

################################################################################

This script manipulates and cleans the observational data (discharge, water quality)
in order to get it reading for model construction. It also splits data into training,
validation, and testing sets.

**Inputs**

Three dataframes with monitoring data and watershed attributes:

1) `flow_data_clean` (*from 00.1_obs_data_download_and_clean*)

2) `lc_tribs_wq_all` (*from 00.1_obs_data_download_and_clean download*)

3) `watershed_chars` (*from 00.2_watershed_attributes_downloads*)

**Outputs**

1) Dataframe with observational concentration data and all possible drivers for 
total phosphorus and chloride (`tp_drivers`)


################################################################################

# Housekeeping

### Packages
```{r, eval=FALSE}

### Data mgmt
require(tidyverse)
require(zoo)

```

# Data Cleaning & Prep

### Transform to log and add in antecedent features

```{r, eval=FALSE}
#### First, transform normalized discharge (m3/s/km2) to log-scale
#### Then, calculate daily, weekly, and monthly discharge
#### Calculate the the change in discharge from time t to time t-1
#### Calculate that change normalized by discharge at time t-1
#### And then also transform that into a categorical "rise/fall"
#### based on whether it is positive (rise) or negative (fall)
#### And finally determine a "season" categorical variable


flow_data_transform <- flow_data_clean %>% 
  mutate(discharge_cms_km2 = discharge_cms/(drnarea_km2)) %>%
  dplyr::select(tributary, site_no,
                date, waterYear,
                discharge_cms_km2) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(tributary) %>%
  arrange(date, .by_group = TRUE) %>%
  mutate(log_daily_q = log10(discharge_cms_km2)) %>%
  mutate(mean_prior_weekly_q = rollapply(log_daily_q,
                                         width = list(-(7:1)),
                                         FUN = mean, align = "right",
                                         fill= NA)) %>%
  mutate(mean_prior_monthly_q = rollapply(log_daily_q,
                                         width = list(-(30:1)),
                                         FUN = mean, align = "right",
                                         fill= NA)) %>%
  mutate(delta_daily_q = discharge_cms_km2 - lag(discharge_cms_km2)) %>%
  mutate(lag_daily_q = lag(log_daily_q)) %>%
  mutate(dq_q = abs(delta_daily_q/lag(discharge_cms_km2))*sign(delta_daily_q)) %>%
  mutate(delta_daily_q_cat = case_when(dq_q > 0.10 ~ 1,
                                       dq_q < -0.10 ~ -1,
                                       (dq_q <= 0.10 & dq_q >= -0.10) ~ 0)) %>%
  mutate(delta_daily_q = log_daily_q - lag(log_daily_q)) %>% ### Update
  mutate(delta_daily_q_cat = as.factor(delta_daily_q_cat)) %>%
  mutate(day_of_year = yday(date)) %>%
  dplyr::slice(-(1:30)) %>% ### Remove first thirty days of record 
  dplyr::select(tributary, site_no, 
                date, waterYear, 
                day_of_year,
                log_daily_q,
                mean_prior_weekly_q, 
                mean_prior_monthly_q,
                delta_daily_q, 
                delta_daily_q_cat,
                lag_daily_q) %>%
  rename(water_year = waterYear) %>% ### Better follows our naming conventions
  dplyr::ungroup() %>%
  tidyr::drop_na(mean_prior_monthly_q) %>%
  tidyr::drop_na(tributary) %>%
  mutate(date = as_date(date)) %>%
  dplyr::mutate(season = case_when(day_of_year %in% seq(60,151,1) ~ "Spring",
                                   day_of_year %in% seq(152,243,1) ~ "Summer",
                                   day_of_year %in% seq(244,334,1) ~ "Fall",
                                   day_of_year > 334 | day_of_year < 60 ~ "Winter")) %>%
  dplyr::select(!day_of_year) ### Remove day of year
  

tp_data <- read_csv(here("input-data/tp_and_chlor_water_quality_data_clean.csv"))

tp_data2 <- tp_data %>%
  filter(str_detect(constituent, "Phos"))
```


### Transfrom VTDEC water quality monitoring data to log

```{r}

lc_tribs_wq_all_clean <- lc_tribs_wq_all_clean %>%
  mutate(log_conc = log10(conc)) %>% ### Transform to log
  dplyr::select(!conc) ### Remove raw concentration

```

# Combine datasets

### Join discharge and water quality data
```{r, eval=FALSE}

#### Join them together

tribs_wq_and_q_all <- inner_join(flow_data_transform, 
                                 lc_tribs_wq_all_clean,
                                 by = c("tributary", "date")) %>%
  dplyr::ungroup()
  
  
```

### Join combined water quality & discharge data to watershed attributes
```{r, eval=FALSE}

#### Do it 

all_drivers <- tribs_wq_and_q_all %>%
  inner_join(., watershed_chars,
             by = "tributary") %>%
  filter(water_year < 2024) ### Remove data from water year 2024

#### Split into Total Phosphorus and Chloride dataframes
#### Also add a numerical ID field that uniquely represents each tributary
#### This will make it easier to make certain model train/valid/splits

##### For total phosphorus

tp_drivers <- all_drivers %>%
  filter(constituent == "Phosphorus_Total") %>%
  group_by(tributary) %>%
  mutate(group_id = cur_group_id()) %>%
  dplyr::ungroup() 



```

# Make final modeling dataframes

### Remove unsplittable features
```{r, eval=FALSE}

#### We want check to make sure each feature has at least two unique values across
#### all cross validation data sets 
#### This removes features that would have limited explainability in a leave-one-out
#### cross validation scenario and might instead "identify" a specific basin 
#### Rather than reflect, in some way, physical/chemical process(es)
#### We've written a small function to do so

#### Find the unsplittable features

##### This can really be any of the constituent driver dataframes
##### because these are likely to be static attributes
##### but just to be safe lets do it for both


##### Make an empty list to save things
  
small_feats <- list()
    
##### Loop over each basin 
    
for(i in 1:18) {
        
        #### Track across basins
        
        removed_trib <- tp_drivers %>%
          filter(group_id == i) %>%
          .$tributary %>%
          .[1]
              
              
        print(removed_trib)
              
        #### Determine how many unique values there are for each feature
              
        small_feats[[i]] <- tp_drivers %>%
          filter(group_id != i) %>%
          dplyr::select(!c(constituent, 
                           site_no,
                           drnarea_km2)) %>%
          dplyr::select(!c(log_conc,
                           date, 
                           water_year,
                           tributary,
                           group_id)) %>%
          summarise(across(everything(), ~length(unique(.x)))) %>% ### How many unique
          pivot_longer(everything(), 
                       values_to = "unique_feature_values",
                       names_to = "feature") %>%
          mutate(feature_value_rank = dense_rank(unique_feature_values)) %>%
          filter(feature_value_rank == 1) %>%
          dplyr::select(!feature_value_rank) %>%
          mutate(removed_trib = removed_trib)
                
      
      } ## End for loop
      
      all_small_feats <- bind_rows(small_feats)
      
      #### Get features that only have one unique value across at least one
      #### Cross-validation split 
      
      unsplittable_feats_tp <- all_small_feats %>%
        filter(unique_feature_values < 2) %>%
        .$feature

#### Remove those from the drivers data frame

tp_drivers <- tp_drivers %>%
  dplyr::select(!unsplittable_feats_tp)


#### Check to make sure it worked 

unsplittable_feats_tp %in% names(tp_drivers)


tp_drivers <- tp_drivers %>%
  mutate(wateryear = as.character(water_year))

tp_drivers <- read_csv(here("input-data/tp_drivers.csv"))

```

# Then, divide into training & testing 

```{r}

#### Do it

tp_train_valid <- tp_drivers %>%
  filter(water_year < 2019)

tp_test <- tp_drivers %>%
  filter(water_year >= 2019)



```

# Transform further

#### Now transform, by subracting mean and std deviation of each vat  
```{r, eval=FALSE}

#### Scale training data

tp_train_scaled <- tp_train_valid %>%
  mutate(across(where(is.numeric), ~(.x - mean(.x))/sd(.x)))  %>%
  mutate(wateryear = as.numeric(wateryear))

tp_train_scalars <- tp_train_valid %>%
  summarise(across(where(is.numeric), 
                   list(mean = ~mean(.x),
                        sd = ~sd(.x)),
            .names = "{.col}xxx{.fn}"))%>%
  pivot_longer(everything(),
               #names_to = "metric",
               names_to = c(".value", "metric"),
               names_sep = "xxx") 

tp_train_scalars_conc <- tp_train_scalars %>%
  dplyr::select(metric, log_conc)

write_csv(tp_train_scalars_conc, here("output-data/train_scalars.csv"))

##### Scale testing data

tp_test_scaled <- tp_test %>%
  mutate(across(where(is.numeric), ~(.x - mean(.x))/sd(.x))) %>%
  mutate(wateryear = as.numeric(wateryear))

tp_test_scalars <- tp_test %>%
  summarise(across(where(is.numeric), 
                   list(mean = ~mean(.x),
                        sd = ~sd(.x)),
            .names = "{.col}xxx{.fn}"))%>%
  pivot_longer(everything(),
               #names_to = "metric",
               names_to = c(".value", "metric"),
               names_sep = "xxx")

tp_test_scalars_conc <- tp_test_scalars %>%
  dplyr::select(metric, log_conc)

write_csv(tp_test_scalars_conc, here("output-data/test_scalars.csv"))


```

# Now, finally, pick the vars for the model types

#### Simplest model - just flow and conc 

```{r}

tp_simplest_train <- tp_train_scaled %>%
  dplyr::select(tributary, date, wateryear, log_conc, log_daily_q)

tp_simplest_test <- tp_test_scaled %>%
  dplyr::select(names(tp_simplest_train))

write_csv(tp_simplest_test, "input-data/tp_simplest_test.csv")


```

##### More complex - include antecedent conditions & season (dynamic params)

```{r}

tp_mrcomp_train <- tp_train_scaled %>%
  dplyr::select(names(flow_data_transform), wateryear) 

tp_mrcomp_train <- tp_test_scaled %>%
  dplyr::select(names(tp_mrcomp_train)) 

```

##### Most complex - all ants and static watershed chars

```{r}

tp_mstcomp_train <- tp_train_scaled

tp_mstcompt_test <- tp_test_scaled

```

