{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0d1516d8",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"01_model_development_simple\"\n",
    "author: \"JTK\"\n",
    "date: \"2025-05-02\"\n",
    "output: html_document\n",
    "editor_options: \n",
    "  chunk_output_type: console\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1cc233",
   "metadata": {},
   "source": [
    "################################################################################\n",
    "\n",
    "This script builds boosted regression trees (specifically, the LightGBM implementation)\n",
    "to forecast total phosphorus concentration in a subset of 3 tributary watersheds\n",
    "to Lake Champlain (see Fig. 1 in the [ReadMe](https://github.com/jtkemper/wqforecast-tutorial/blob/main/README.md))\n",
    "\n",
    "This script builds three model \"types\": \n",
    "\n",
    "1) A (very) simple model designed to predict/forecast water quality concentration where using only flow data from the 18 tributary watersheds in the Lake Champlain basin\n",
    "\n",
    "**AND** \n",
    "\n",
    "2) A more complex model designed to predict/forecast water quality concentration using flow data, antecedent flow conditions, and season\n",
    "\n",
    "**AND**\n",
    "\n",
    "3) An additionally complex model designed to predict/forecast water quality concentration using flow data, antecedent conditions, season, and various static watershed attributes.\n",
    "\n",
    "For the two more complex models, we will use antecedent conditions and watershed characteristics to potentially learn the complex interactions that drive water quality, and then use a backwards variable selection process to build the most robust model possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b669a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The ultimate goal is to develop models that can be fed streamflow forecast data and forecast \n",
    "future in-stream concentrations. \n",
    "\n",
    "Models are trained on observational data and then predictions are tested on \"test\" datasets\n",
    "which have been wholly witheld from training. This, in essence, provides an upper benchmark for \n",
    "model performance in terms of forecasting ability: how well can these models do in predicting \n",
    "(rather than forecasting) concentration if discharge is \"perfect\"\n",
    "\n",
    "A simple model evaluation is done at the end, as is a toy forecasting example.\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "1) `tp_simplest_train`, `tp_simplest_test`; `tp_mrcomp_train`, `tp_mrcomp_test`; `tp_mstcomp_train`, `tp_mstcomp_test` (*from .csv*): provided dataframes from file with total phosphorus concentration data and various possible predictive features\n",
    "\n",
    "`-simplest` dataframes contain only observed concentration and observed discharge\n",
    "\n",
    "`-mrcomp` dataframes contain observed concentration, discharge, and antecedent flow conditions at a variety of lookback lengths (days, weeks, months)\n",
    "\n",
    "`mstcomp` dataframes contain observed concentration, discharge, and antecedent flow conditions, and a number of static watershed features that heve been shown in the literature to possibly influence phosphorus concentrations \n",
    "\n",
    "2) `flow_forecasts_JunJul2024` - operational NWM forecasts for June & July 2024 (and engineered additional features, like antecedent conditions) \n",
    "\n",
    "We can use these to create a toy forecasting example for our watersheds\n",
    "\n",
    "*Important* All numeric features have been log-transformed and then normalized by removing the mean and dividing by the standard deviation [e.g., (x_i â€“ mean(all_x))/sd(all_x)]\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "1) Model architectures for total phosphorus prediction using simple and more complex models \n",
    "\n",
    "We can output text files with these saved architecture to file if we so wish\n",
    "\n",
    "2) Performance statistics for total phosphorus concentration predictions on test data \n",
    "\n",
    "3) Predicted time series for total phosphorus for test years (2019-2023)\n",
    "\n",
    "4) Toy forecast for June-July 2024\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Housekeeping\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e5e91",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### Data mgmt\n",
    "require(tidyverse)\n",
    "\n",
    "### Model development\n",
    "require(hydroGOF)\n",
    "require(zoo)\n",
    "require(lightgbm)\n",
    "require(R6)\n",
    "require(SHAPforxgboost)\n",
    "\n",
    "\n",
    "### Data viz\n",
    "require(ggthemes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1725c3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69761fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Model datasets (observational data)\n",
    "\n",
    "#### Simplest model data, training & testing \n",
    "\n",
    "tp_simplest_train <- read_csv(\"input-data/tp_simplest_train.csv\")\n",
    "\n",
    "tp_simplest_test <- read_csv(\"input-data/tp_simplest_test.csv\")\n",
    "\n",
    "#### More complex (has antecedents & season)\n",
    "\n",
    "tp_mrcomp_train <- read_csv(\"input-data/tp_mrcomp_train.csv\")\n",
    "\n",
    "tp_mrcomp_test <- read_csv(\"input-data/tp_mrcomp_test.csv\")\n",
    "\n",
    "#### Most complex (antecedents & watershed attributes)\n",
    "\n",
    "tp_mstcomp_train <- read_csv(\"input-data/tp_mstcomp_train.csv\")\n",
    "\n",
    "tp_mstcomp_test <- read_csv(\"input-data/tp_mstcomp_test.csv\")\n",
    "\n",
    "### Scalars \n",
    "\n",
    "conc_scalars_train <- read_csv(\"input-data/train_scalars.csv\")\n",
    "\n",
    "conc_scalars_test <- read_csv(\"input-data/test_scalars.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a666eb6",
   "metadata": {},
   "source": [
    "# Check out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Check the variables in each dataset \n",
    "\n",
    "head(tp_simplest_train)\n",
    "\n",
    "head(tp_mrcomp_train)\n",
    "\n",
    "head(tp_mrcomp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83d0d7",
   "metadata": {},
   "source": [
    "# The simplest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########## Model setup #########################################################\n",
    "\n",
    "### Declare the predictor and response variables \n",
    "### Make sure to exclude variables we left in there \n",
    "### For interpretability\n",
    "\n",
    "preds <- data.matrix(tp_simplest_train %>%\n",
    "                       dplyr::select(log_daily_q))\n",
    "\n",
    "\n",
    "                                                                    \n",
    "                        \n",
    "                        \n",
    "response <- tp_simplest_train$log_conc\n",
    "                        \n",
    "### Set up the environment - this is just preparing the dataset API for use by lightgbm.\n",
    "#### This is our training data\n",
    "simplest_train_lgbm <- lgb.Dataset(preds, label = response)\n",
    "                        \n",
    "#### Declare the test data\n",
    "simplest_test_lgbm <- data.matrix(tp_simplest_test %>%\n",
    "                       dplyr::select(log_daily_q))\n",
    "                    \n",
    "### Declare the hyperparameters \n",
    "### These are just default for now\n",
    "\n",
    "hyperparams <- list(objective = \"regression\",\n",
    "                    num_leaves = 31L,\n",
    "                    learning_rate = 0.1,\n",
    "                    min_data_in_leaf = 20L,\n",
    "                    num_threads = 10L)\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "### Now, let's do some actual modeling stuff\n",
    "\n",
    "\n",
    "\n",
    "#### Train the model\n",
    "                        \n",
    "set.seed(913)\n",
    "                        \n",
    "simple_model_lgbm <- lgb.train(hyperparams,\n",
    "                               data = simplest_train_lgbm,\n",
    "                               verbose = 1L,\n",
    "                               nrounds = 100L)\n",
    "                        \n",
    "### Predict with the model on test data\n",
    "\n",
    "simple_model_predicted <- predict(simple_model_lgbm, \n",
    "                                  data = simplest_test_lgbm) %>%\n",
    "  as_tibble() %>% \n",
    "  rename(log_predicted_conc = 1)\n",
    "                        \n",
    "                        \n",
    "### Bind predictions on test data to observations\n",
    "\n",
    "predicted_observed <- bind_cols(tp_simplest_test %>% \n",
    "                                  dplyr::rename(log_observed_conc = log_conc),\n",
    "                                simple_model_predicted) \n",
    "\n",
    "### Now use the scalars to convert back to linear scale\n",
    "\n",
    "predicted_observed_resc <- predicted_observed %>%\n",
    "  mutate(observed_conc = 10^(log_observed_conc*conc_scalars_test$sd + conc_scalars_test$mean),\n",
    "         predicted_conc = 10^(log_predicted_conc*conc_scalars_test$sd + conc_scalars_test$mean))\n",
    "\n",
    "                    \n",
    "### Evaluate - we are going to use multiple error metrics\n",
    "\n",
    "#### For each watershed\n",
    "\n",
    "model_stats_simple <- predicted_observed_resc %>%\n",
    "  ungroup() %>%\n",
    "  dplyr::group_by(tributary) %>%\n",
    "  summarise(mae = hydroGOF::mae(predicted_conc, observed_conc),\n",
    "            nse = hydroGOF::NSE(predicted_conc, observed_conc),\n",
    "            kge = hydroGOF::KGE(predicted_conc, \n",
    "                                observed_conc),\n",
    "            pbias = hydroGOF::pbias(predicted_conc,\n",
    "                                    observed_conc)) %>%\n",
    "  dplyr::ungroup() \n",
    "\n",
    "#### Median across all \n",
    "\n",
    "simplest_sum_stats <- model_stats_simple %>%\n",
    "  reframe(across(where(is.numeric),\n",
    "                 list(median = ~median(.x)),\n",
    "                 .names = \"{.fn}_{.col}\"\n",
    "                 )) %>%\n",
    "  mutate(model_feats = colnames(preds),\n",
    "         model_feats_num = length(colnames(preds)),\n",
    "         model_type = \"simplest\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c813483",
   "metadata": {},
   "source": [
    "# The more complex model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ad8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Train the model using our custom function \n",
    "\n",
    "mrcomp_feat_selec <- lgbm_selector(tp_mrcomp_train,\n",
    "              selection = TRUE,\n",
    "              is_tuned = FALSE,\n",
    "              selector = \"shap\",\n",
    "              conc_scalars = conc_scalars_train)\n",
    "\n",
    "#### Extract the relevant outputs from the feature selection process\n",
    "\n",
    "mrcomp_stats_by_mod <- mrcomp_feat_selec[[2]]\n",
    "\n",
    "##### Plot the performance by each model \n",
    "\n",
    "plot_stats(mrcomp_stats_by_mod)\n",
    "\n",
    "##### Pick the model\n",
    "#********** Choose the model number you think is best **********************#\n",
    "\n",
    "mrcomp_chosen_mod <- mrcomp_feat_selec[[1]] %>% filter(model == 5)\n",
    "\n",
    "###### Examine chosen model performance on test data\n",
    "\n",
    "mrcomp_testing <- lgbm_runner(train_df = tp_mrcomp_train,\n",
    "                              test_df = tp_mrcomp_test,\n",
    "                              chosen_mod = mrcomp_chosen_mod,\n",
    "                              is_tuned = FALSE,\n",
    "                              conc_scalars = conc_scalars_test\n",
    "                              )\n",
    "\n",
    "###### Extract summary statistics \n",
    "\n",
    "mrcomp_sum_stats <- mrcomp_testing[[2]] %>%\n",
    "  mutate(model_feats = mrcomp_stats_by_mod %>%\n",
    "           filter(model == mrcomp_chosen_mod$model[1]) %>%\n",
    "           .$all_vars,\n",
    "         model_feats_num = nrow(mrcomp_chosen_mod),\n",
    "         model_type = \"more_comp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03c26e",
   "metadata": {},
   "source": [
    "# The most complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c1a66",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Train the model using our custom function \n",
    "\n",
    "mstcomp_feat_selec <- lgbm_selector(tp_mstcomp_train,\n",
    "                                   selector = \"shap\",\n",
    "                                   conc_scalars = conc_scalars_train)\n",
    "\n",
    "#### Extract the relevant outputs from the feature selection process\n",
    "\n",
    "mstcomp_stats_by_mod <- mstcomp_feat_selec[[2]]\n",
    "\n",
    "##### Plot the performance by each model \n",
    "\n",
    "plot_stats(mstcomp_stats_by_mod)\n",
    "\n",
    "##### Pick the model\n",
    "#********** Choose the model number you think is best **********************#\n",
    "\n",
    "mstcomp_chosen_mod <- mstcomp_feat_selec[[1]] %>% filter(model == 73)\n",
    "\n",
    "##### Examine chosen model performance on test data\n",
    "\n",
    "###### Predict with chosen model\n",
    "\n",
    "\n",
    "mstcomp_testing <- lgbm_runner(train_df = tp_mstcomp_train,\n",
    "                              test_df = tp_mstcomp_test,\n",
    "                              chosen_mod = mstcomp_chosen_mod,\n",
    "                              is_tuned = FALSE,\n",
    "                              conc_scalars = conc_scalars_test\n",
    "                              )\n",
    "\n",
    "###### Extract summary statistics \n",
    "\n",
    "mstcomp_sum_stats <- mstcomp_testing[[2]] %>%\n",
    "  mutate(model_feats = mstcomp_stats_by_mod %>%\n",
    "           filter(model == mstcomp_chosen_mod$model[1]) %>%\n",
    "           .$all_vars,\n",
    "         model_feats_num = nrow(mstcomp_chosen_mod),\n",
    "         model_type = \"most_comp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2a4af",
   "metadata": {},
   "source": [
    "# Examine performance differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bfb4ae",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "sum_stats_all <- bind_rows(simplest_sum_stats,\n",
    "                           mrcomp_sum_stats,\n",
    "                           mstcomp_sum_stats) %>%\n",
    "  relocate(model_type, 1) %>%\n",
    "  relocate(model_feats_num, .after = model_type)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e5ef4",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
