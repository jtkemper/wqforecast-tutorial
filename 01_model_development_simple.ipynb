{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6139bf67",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"01_model_development_simple\"\n",
    "author: \"JTK\"\n",
    "date: \"2025-05-02\"\n",
    "output: html_document\n",
    "editor_options: \n",
    "  chunk_output_type: console\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eefde1",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b5ddc",
   "metadata": {},
   "source": [
    "################################################################################\n",
    "\n",
    "This script builds boosted regression trees (specifically, the LightGBM implementation)\n",
    "to forecast total phosphorus concentration in a subset of 3 tributary watersheds\n",
    "to Lake Champlain (see Fig. 1 in the [ReadMe](https://github.com/jtkemper/wqforecast-tutorial/blob/main/README.md))\n",
    "\n",
    "This and a partner script builds two model \"types\": \n",
    "\n",
    "1) a simple model designed to predict/forecast water quality concentration where data from a \n",
    "given watershed is used to train the model and predict in that same watershed\n",
    "\n",
    "AND \n",
    "\n",
    "2) a more complex model designed to predict/forecast water quality concentration where data from all 18 tributaries to Lake Champlain is used to train a model to predict concentration in one watershed.\n",
    "\n",
    "For the simple model, we will used only dynamic hydrology features to predict concentration. For the more complex model, we will use watershed characteristics to build a more diverse dataset, and then use a backwards variable selection process to build the most robust model possible\n",
    "\n",
    "The basic workflow is as follows: we use a backwards variable selection method\n",
    "to identify the most relevant variables for each LightGBM model, we then train the model on those \n",
    "variables and tune the hyperparameters, and then finally train the model with tuned hyperparameters.\n",
    "The ultimate goal is to develop models that can be fed streamflow forecast data and forecast \n",
    "future in-stream concentrations. \n",
    "\n",
    "Models are trained on observational data and then predictions are tested on \"test\" datasets\n",
    "which have been wholly witheld from training. This, in essence, provides an upper benchmark for \n",
    "model performance in terms of forecasting ability: how well can these models do in predicting \n",
    "(rather than forecasting) concentration if discharge is \"perfect\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d287d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Model evaluation is done is subsequent scripts, as is forecasting (and forecast evaluation).\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "1) `tp_drivers` (*from .csv*): dataframe with total phosphorus \n",
    "concentration data and all possible predictive features\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "1) Model architectures for total phosphorus prediction using simple and more complex models (`tp_lgbm_simple`, `tp_lgbm_complex`).\n",
    "Also output text files with these saved architecture to xxx/data/model/lumped and \n",
    "xxx/data/models/loocv. \n",
    "\n",
    "2) Performance statistics for total phosphorus concentration predictions on test data (`summary_stats_simple_models`,\n",
    "`summary_stats_complex models`). \n",
    "\n",
    "3) Predicted time series for total phosphorus for test years (2019-2023)\n",
    "(`tp_pred_ts_simple`, `tp_pred_ts_complex`)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Housekeeping\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff5867",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### Data mgmt\n",
    "require(tidyverse)\n",
    "\n",
    "### Model development\n",
    "require(hydroGOF)\n",
    "require(zoo)\n",
    "require(lightgbm)\n",
    "require(R6)\n",
    "require(SHAPforxgboost)\n",
    "\n",
    "\n",
    "### Data viz\n",
    "require(ggthemes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f280b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a408c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Model datasets (observational data)\n",
    "\n",
    "#### Simplest model data, training & testing \n",
    "\n",
    "tp_simplest_train <- read_csv(\"input-data/tp_simplest_train.csv\")\n",
    "\n",
    "tp_simplest_test <- read_csv(\"input-data/tp_simplest_test.csv\")\n",
    "\n",
    "#### More complex (has antecedents & season)\n",
    "\n",
    "tp_mrcomp_train <- read_csv(\"input-data/tp_mrcomp_train.csv\")\n",
    "\n",
    "tp_mrcomp_test <- read_csv(\"input-data/tp_mrcomp_test.csv\")\n",
    "\n",
    "#### Most complex (antecedents & watershed attributes)\n",
    "\n",
    "tp_mstcomp_train <- read_csv(\"input-data/tp_mstcomp_train.csv\")\n",
    "\n",
    "tp_mstcomp_test <- read_csv(\"input-data/tp_mstcomp_test.csv\")\n",
    "\n",
    "### Scalars \n",
    "\n",
    "conc_scalars_train <- read_csv(\"input-data/train_scalars.csv\")\n",
    "\n",
    "conc_scalars_test <- read_csv(\"input-data/test_scalars.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbfa4a",
   "metadata": {},
   "source": [
    "# Check out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Check the variables in each dataset \n",
    "\n",
    "head(tp_simplest_train)\n",
    "\n",
    "head(tp_mrcomp_train)\n",
    "\n",
    "head(tp_mrcomp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d8eda",
   "metadata": {},
   "source": [
    "# The simplest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02deb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########## Model setup #########################################################\n",
    "\n",
    "### Declare the predictor and response variables \n",
    "### Make sure to exclude variables we left in there \n",
    "### For interpretability\n",
    "\n",
    "preds <- data.matrix(tp_simplest_train %>%\n",
    "                       dplyr::select(log_daily_q))\n",
    "\n",
    "\n",
    "                                                                    \n",
    "                        \n",
    "                        \n",
    "response <- tp_simplest_train$log_conc\n",
    "                        \n",
    "### Set up the environment - this is just preparing the dataset API for use by lightgbm.\n",
    "#### This is our training data\n",
    "simplest_train_lgbm <- lgb.Dataset(preds, label = response)\n",
    "                        \n",
    "#### Declare the test data\n",
    "simplest_test_lgbm <- data.matrix(tp_simplest_test %>%\n",
    "                       dplyr::select(log_daily_q))\n",
    "                    \n",
    "### Declare the hyperparameters \n",
    "### These are just default for now\n",
    "\n",
    "hyperparams <- list(objective = \"regression\",\n",
    "                    num_leaves = 31L,\n",
    "                    learning_rate = 0.1,\n",
    "                    min_data_in_leaf = 20L,\n",
    "                    num_threads = 10L)\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "### Now, let's do some actual modeling stuff\n",
    "\n",
    "\n",
    "\n",
    "#### Train the model\n",
    "                        \n",
    "set.seed(913)\n",
    "                        \n",
    "simple_model_lgbm <- lgb.train(hyperparams,\n",
    "                               data = simplest_train_lgbm,\n",
    "                               verbose = 1L,\n",
    "                               nrounds = 100L)\n",
    "                        \n",
    "### Predict with the model on test data\n",
    "\n",
    "simple_model_predicted <- predict(simple_model_lgbm, \n",
    "                                  data = simplest_test_lgbm) %>%\n",
    "  as_tibble() %>% \n",
    "  rename(log_predicted_conc = 1)\n",
    "                        \n",
    "                        \n",
    "### Bind predictions on test data to observations\n",
    "\n",
    "predicted_observed <- bind_cols(tp_simplest_test %>% \n",
    "                                  dplyr::rename(log_observed_conc = log_conc),\n",
    "                                simple_model_predicted) \n",
    "\n",
    "### Now use the scalars to convert back to linear scale\n",
    "\n",
    "predicted_observed_resc <- predicted_observed %>%\n",
    "  mutate(observed_conc = 10^(log_observed_conc*conc_scalars_test$sd + conc_scalars_test$mean),\n",
    "         predicted_conc = 10^(log_predicted_conc*conc_scalars_test$sd + conc_scalars_test$mean))\n",
    "\n",
    "                    \n",
    "### Evaluate - we are going to use multiple error metrics\n",
    "\n",
    "#### For each watershed\n",
    "\n",
    "model_stats_simple <- predicted_observed_resc %>%\n",
    "  ungroup() %>%\n",
    "  dplyr::group_by(tributary) %>%\n",
    "  summarise(mae = hydroGOF::mae(predicted_conc, observed_conc),\n",
    "            nse = hydroGOF::NSE(predicted_conc, observed_conc),\n",
    "            kge = hydroGOF::KGE(predicted_conc, \n",
    "                                observed_conc),\n",
    "            pbias = hydroGOF::pbias(predicted_conc,\n",
    "                                    observed_conc)) %>%\n",
    "  dplyr::ungroup() \n",
    "\n",
    "#### Median across all \n",
    "\n",
    "simplest_sum_stats <- model_stats_simple %>%\n",
    "  reframe(across(where(is.numeric),\n",
    "                 list(median = ~median(.x)),\n",
    "                 .names = \"{.fn}_{.col}\"\n",
    "                 )) %>%\n",
    "  mutate(model_feats = colnames(preds),\n",
    "         model_feats_num = length(colnames(preds)),\n",
    "         model_type = \"simplest\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4406048e",
   "metadata": {},
   "source": [
    "# The more complex model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Train the model using our custom function \n",
    "\n",
    "mrcomp_feat_selec <- lgbm_selector(tp_mrcomp_train,\n",
    "              selection = TRUE,\n",
    "              is_tuned = FALSE,\n",
    "              selector = \"shap\",\n",
    "              conc_scalars = conc_scalars_train)\n",
    "\n",
    "#### Extract the relevant outputs from the feature selection process\n",
    "\n",
    "mrcomp_stats_by_mod <- mrcomp_feat_selec[[2]]\n",
    "\n",
    "##### Plot the performance by each model \n",
    "\n",
    "plot_stats(mrcomp_stats_by_mod)\n",
    "\n",
    "##### Pick the model\n",
    "#********** Choose the model number you think is best **********************#\n",
    "\n",
    "mrcomp_chosen_mod <- mrcomp_feat_selec[[1]] %>% filter(model == 5)\n",
    "\n",
    "###### Examine chosen model performance on test data\n",
    "\n",
    "mrcomp_testing <- lgbm_runner(train_df = tp_mrcomp_train,\n",
    "                              test_df = tp_mrcomp_test,\n",
    "                              chosen_mod = mrcomp_chosen_mod,\n",
    "                              is_tuned = FALSE,\n",
    "                              conc_scalars = conc_scalars_test\n",
    "                              )\n",
    "\n",
    "###### Extract summary statistics \n",
    "\n",
    "mrcomp_sum_stats <- mrcomp_testing[[2]] %>%\n",
    "  mutate(model_feats = mrcomp_stats_by_mod %>%\n",
    "           filter(model == mrcomp_chosen_mod$model[1]) %>%\n",
    "           .$all_vars,\n",
    "         model_feats_num = nrow(mrcomp_chosen_mod),\n",
    "         model_type = \"more_comp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b92fe",
   "metadata": {},
   "source": [
    "# The most complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa930a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Train the model using our custom function \n",
    "\n",
    "mstcomp_feat_selec <- lgbm_selector(tp_mstcomp_train,\n",
    "                                   selector = \"shap\",\n",
    "                                   conc_scalars = conc_scalars_train)\n",
    "\n",
    "#### Extract the relevant outputs from the feature selection process\n",
    "\n",
    "mstcomp_stats_by_mod <- mstcomp_feat_selec[[2]]\n",
    "\n",
    "##### Plot the performance by each model \n",
    "\n",
    "plot_stats(mstcomp_stats_by_mod)\n",
    "\n",
    "##### Pick the model\n",
    "#********** Choose the model number you think is best **********************#\n",
    "\n",
    "mstcomp_chosen_mod <- mstcomp_feat_selec[[1]] %>% filter(model == 73)\n",
    "\n",
    "##### Examine chosen model performance on test data\n",
    "\n",
    "###### Predict with chosen model\n",
    "\n",
    "\n",
    "mstcomp_testing <- lgbm_runner(train_df = tp_mstcomp_train,\n",
    "                              test_df = tp_mstcomp_test,\n",
    "                              chosen_mod = mstcomp_chosen_mod,\n",
    "                              is_tuned = FALSE,\n",
    "                              conc_scalars = conc_scalars_test\n",
    "                              )\n",
    "\n",
    "###### Extract summary statistics \n",
    "\n",
    "mstcomp_sum_stats <- mstcomp_testing[[2]] %>%\n",
    "  mutate(model_feats = mstcomp_stats_by_mod %>%\n",
    "           filter(model == mstcomp_chosen_mod$model[1]) %>%\n",
    "           .$all_vars,\n",
    "         model_feats_num = nrow(mstcomp_chosen_mod),\n",
    "         model_type = \"most_comp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b781de",
   "metadata": {},
   "source": [
    "# Examine performance differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacc48f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "sum_stats_all <- bind_rows(simplest_sum_stats,\n",
    "                           mrcomp_sum_stats,\n",
    "                           mstcomp_sum_stats) %>%\n",
    "  relocate(model_type, 1) %>%\n",
    "  relocate(model_feats_num, .after = model_type)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5188c11",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "name,eval,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
